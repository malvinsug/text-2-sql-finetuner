{
  "best_global_step": 1116,
  "best_metric": 0.0542522557079792,
  "best_model_checkpoint": "content/drive/models/training_output_4/checkpoint-1116",
  "epoch": 9.0,
  "eval_steps": 500,
  "global_step": 1116,
  "is_hyper_param_search": false,
  "is_local_process_zero": true,
  "is_world_process_zero": true,
  "log_history": [
    {
      "epoch": 0.08080808080808081,
      "grad_norm": 13.015850067138672,
      "learning_rate": 1.9879032258064516e-05,
      "loss": 5.578479766845703,
      "step": 10
    },
    {
      "epoch": 0.16161616161616163,
      "grad_norm": 12.306844711303711,
      "learning_rate": 1.974462365591398e-05,
      "loss": 4.433839797973633,
      "step": 20
    },
    {
      "epoch": 0.24242424242424243,
      "grad_norm": 11.609118461608887,
      "learning_rate": 1.9610215053763443e-05,
      "loss": 3.170028305053711,
      "step": 30
    },
    {
      "epoch": 0.32323232323232326,
      "grad_norm": 9.40298080444336,
      "learning_rate": 1.9475806451612903e-05,
      "loss": 1.8761165618896485,
      "step": 40
    },
    {
      "epoch": 0.40404040404040403,
      "grad_norm": 5.286498069763184,
      "learning_rate": 1.9341397849462366e-05,
      "loss": 0.8735734939575195,
      "step": 50
    },
    {
      "epoch": 0.48484848484848486,
      "grad_norm": 1.7800805568695068,
      "learning_rate": 1.920698924731183e-05,
      "loss": 0.31956870555877687,
      "step": 60
    },
    {
      "epoch": 0.5656565656565656,
      "grad_norm": 0.40217727422714233,
      "learning_rate": 1.9072580645161292e-05,
      "loss": 0.11500203609466553,
      "step": 70
    },
    {
      "epoch": 0.6464646464646465,
      "grad_norm": 0.1334134191274643,
      "learning_rate": 1.8938172043010755e-05,
      "loss": 0.08108080625534057,
      "step": 80
    },
    {
      "epoch": 0.7272727272727273,
      "grad_norm": 0.11144118756055832,
      "learning_rate": 1.8803763440860215e-05,
      "loss": 0.070091712474823,
      "step": 90
    },
    {
      "epoch": 0.8080808080808081,
      "grad_norm": 0.11706991493701935,
      "learning_rate": 1.8669354838709678e-05,
      "loss": 0.0744411289691925,
      "step": 100
    },
    {
      "epoch": 0.8888888888888888,
      "grad_norm": 0.10010116547346115,
      "learning_rate": 1.853494623655914e-05,
      "loss": 0.07352244853973389,
      "step": 110
    },
    {
      "epoch": 0.9696969696969697,
      "grad_norm": 0.11633072048425674,
      "learning_rate": 1.8400537634408605e-05,
      "loss": 0.06839484572410584,
      "step": 120
    },
    {
      "epoch": 1.0,
      "eval_loss": 0.06795526295900345,
      "eval_runtime": 87.4745,
      "eval_samples_per_second": 7.545,
      "eval_steps_per_second": 3.773,
      "step": 124
    },
    {
      "epoch": 1.0484848484848486,
      "grad_norm": 0.0772845596075058,
      "learning_rate": 1.8266129032258068e-05,
      "loss": 0.06486396193504333,
      "step": 130
    },
    {
      "epoch": 1.1292929292929292,
      "grad_norm": 0.06823030859231949,
      "learning_rate": 1.8131720430107528e-05,
      "loss": 0.06288682222366333,
      "step": 140
    },
    {
      "epoch": 1.2101010101010101,
      "grad_norm": 0.06566287577152252,
      "learning_rate": 1.799731182795699e-05,
      "loss": 0.06069457530975342,
      "step": 150
    },
    {
      "epoch": 1.290909090909091,
      "grad_norm": 0.0790524035692215,
      "learning_rate": 1.7862903225806454e-05,
      "loss": 0.06440240740776063,
      "step": 160
    },
    {
      "epoch": 1.3717171717171717,
      "grad_norm": 0.07850462198257446,
      "learning_rate": 1.7728494623655917e-05,
      "loss": 0.0628172755241394,
      "step": 170
    },
    {
      "epoch": 1.4525252525252526,
      "grad_norm": 0.0760226920247078,
      "learning_rate": 1.759408602150538e-05,
      "loss": 0.07023220658302307,
      "step": 180
    },
    {
      "epoch": 1.5333333333333332,
      "grad_norm": 0.11974471807479858,
      "learning_rate": 1.745967741935484e-05,
      "loss": 0.06517117619514465,
      "step": 190
    },
    {
      "epoch": 1.614141414141414,
      "grad_norm": 0.07063767313957214,
      "learning_rate": 1.73252688172043e-05,
      "loss": 0.06495907306671142,
      "step": 200
    },
    {
      "epoch": 1.694949494949495,
      "grad_norm": 0.06868203729391098,
      "learning_rate": 1.7190860215053763e-05,
      "loss": 0.06686801314353943,
      "step": 210
    },
    {
      "epoch": 1.7757575757575759,
      "grad_norm": 0.06420079618692398,
      "learning_rate": 1.7056451612903226e-05,
      "loss": 0.06207112669944763,
      "step": 220
    },
    {
      "epoch": 1.8565656565656565,
      "grad_norm": 0.08376576751470566,
      "learning_rate": 1.692204301075269e-05,
      "loss": 0.06316893100738526,
      "step": 230
    },
    {
      "epoch": 1.9373737373737374,
      "grad_norm": 0.08368518203496933,
      "learning_rate": 1.6787634408602153e-05,
      "loss": 0.06262634396553039,
      "step": 240
    },
    {
      "epoch": 2.0,
      "eval_loss": 0.0632142722606659,
      "eval_runtime": 88.0376,
      "eval_samples_per_second": 7.497,
      "eval_steps_per_second": 3.748,
      "step": 248
    },
    {
      "epoch": 2.0161616161616163,
      "grad_norm": 0.0745951384305954,
      "learning_rate": 1.6653225806451612e-05,
      "loss": 0.06384766697883607,
      "step": 250
    },
    {
      "epoch": 2.096969696969697,
      "grad_norm": 0.06934960931539536,
      "learning_rate": 1.6518817204301076e-05,
      "loss": 0.06773784160614013,
      "step": 260
    },
    {
      "epoch": 2.1777777777777776,
      "grad_norm": 0.05930635333061218,
      "learning_rate": 1.638440860215054e-05,
      "loss": 0.06191051602363586,
      "step": 270
    },
    {
      "epoch": 2.2585858585858585,
      "grad_norm": 0.05867518112063408,
      "learning_rate": 1.6250000000000002e-05,
      "loss": 0.06206596493721008,
      "step": 280
    },
    {
      "epoch": 2.3393939393939394,
      "grad_norm": 0.05699066072702408,
      "learning_rate": 1.6115591397849465e-05,
      "loss": 0.05760701894760132,
      "step": 290
    },
    {
      "epoch": 2.4202020202020202,
      "grad_norm": 0.06587546318769455,
      "learning_rate": 1.5981182795698925e-05,
      "loss": 0.05909337401390076,
      "step": 300
    },
    {
      "epoch": 2.501010101010101,
      "grad_norm": 0.07658211141824722,
      "learning_rate": 1.5846774193548388e-05,
      "loss": 0.06593965291976929,
      "step": 310
    },
    {
      "epoch": 2.581818181818182,
      "grad_norm": 0.05009419471025467,
      "learning_rate": 1.571236559139785e-05,
      "loss": 0.058328425884246825,
      "step": 320
    },
    {
      "epoch": 2.6626262626262625,
      "grad_norm": 0.06939257681369781,
      "learning_rate": 1.5577956989247314e-05,
      "loss": 0.05181876420974731,
      "step": 330
    },
    {
      "epoch": 2.7434343434343433,
      "grad_norm": 0.06968538463115692,
      "learning_rate": 1.5443548387096778e-05,
      "loss": 0.06490702629089355,
      "step": 340
    },
    {
      "epoch": 2.824242424242424,
      "grad_norm": 0.06620388478040695,
      "learning_rate": 1.5309139784946237e-05,
      "loss": 0.05864723920822144,
      "step": 350
    },
    {
      "epoch": 2.905050505050505,
      "grad_norm": 0.08496524393558502,
      "learning_rate": 1.51747311827957e-05,
      "loss": 0.05889002680778503,
      "step": 360
    },
    {
      "epoch": 2.985858585858586,
      "grad_norm": 0.07690040022134781,
      "learning_rate": 1.5040322580645164e-05,
      "loss": 0.05922978520393372,
      "step": 370
    },
    {
      "epoch": 3.0,
      "eval_loss": 0.06085158884525299,
      "eval_runtime": 88.1587,
      "eval_samples_per_second": 7.486,
      "eval_steps_per_second": 3.743,
      "step": 372
    },
    {
      "epoch": 3.0646464646464646,
      "grad_norm": 0.06398389488458633,
      "learning_rate": 1.4905913978494624e-05,
      "loss": 0.06704699397087097,
      "step": 380
    },
    {
      "epoch": 3.1454545454545455,
      "grad_norm": 0.06622301042079926,
      "learning_rate": 1.4771505376344087e-05,
      "loss": 0.05670986175537109,
      "step": 390
    },
    {
      "epoch": 3.2262626262626264,
      "grad_norm": 0.06247016414999962,
      "learning_rate": 1.4637096774193548e-05,
      "loss": 0.06026037335395813,
      "step": 400
    },
    {
      "epoch": 3.3070707070707073,
      "grad_norm": 0.05598907545208931,
      "learning_rate": 1.4502688172043011e-05,
      "loss": 0.05801964998245239,
      "step": 410
    },
    {
      "epoch": 3.3878787878787877,
      "grad_norm": 0.06981255859136581,
      "learning_rate": 1.4368279569892473e-05,
      "loss": 0.058812510967254636,
      "step": 420
    },
    {
      "epoch": 3.4686868686868686,
      "grad_norm": 0.05953635275363922,
      "learning_rate": 1.4233870967741936e-05,
      "loss": 0.05832362174987793,
      "step": 430
    },
    {
      "epoch": 3.5494949494949495,
      "grad_norm": 0.06131282076239586,
      "learning_rate": 1.40994623655914e-05,
      "loss": 0.05836346745491028,
      "step": 440
    },
    {
      "epoch": 3.6303030303030304,
      "grad_norm": 0.06660293787717819,
      "learning_rate": 1.396505376344086e-05,
      "loss": 0.054709017276763916,
      "step": 450
    },
    {
      "epoch": 3.7111111111111112,
      "grad_norm": 0.07622505724430084,
      "learning_rate": 1.3830645161290324e-05,
      "loss": 0.06122797131538391,
      "step": 460
    },
    {
      "epoch": 3.7919191919191917,
      "grad_norm": 0.05464499816298485,
      "learning_rate": 1.3696236559139785e-05,
      "loss": 0.053363478183746337,
      "step": 470
    },
    {
      "epoch": 3.8727272727272726,
      "grad_norm": 0.06807393580675125,
      "learning_rate": 1.3561827956989249e-05,
      "loss": 0.060813242197036745,
      "step": 480
    },
    {
      "epoch": 3.9535353535353535,
      "grad_norm": 0.06430447846651077,
      "learning_rate": 1.3427419354838712e-05,
      "loss": 0.059005504846572875,
      "step": 490
    },
    {
      "epoch": 4.0,
      "eval_loss": 0.05907474458217621,
      "eval_runtime": 87.5505,
      "eval_samples_per_second": 7.539,
      "eval_steps_per_second": 3.769,
      "step": 496
    },
    {
      "epoch": 4.0323232323232325,
      "grad_norm": 0.04845976084470749,
      "learning_rate": 1.3293010752688173e-05,
      "loss": 0.05912242531776428,
      "step": 500
    },
    {
      "epoch": 4.113131313131313,
      "grad_norm": 0.0573616661131382,
      "learning_rate": 1.3158602150537636e-05,
      "loss": 0.058849912881851194,
      "step": 510
    },
    {
      "epoch": 4.193939393939394,
      "grad_norm": 0.06972318887710571,
      "learning_rate": 1.3024193548387098e-05,
      "loss": 0.05605725049972534,
      "step": 520
    },
    {
      "epoch": 4.274747474747475,
      "grad_norm": 0.058717187494039536,
      "learning_rate": 1.2889784946236561e-05,
      "loss": 0.05776209235191345,
      "step": 530
    },
    {
      "epoch": 4.355555555555555,
      "grad_norm": 0.052418775856494904,
      "learning_rate": 1.2755376344086023e-05,
      "loss": 0.053939682245254514,
      "step": 540
    },
    {
      "epoch": 4.4363636363636365,
      "grad_norm": 0.06309913098812103,
      "learning_rate": 1.2620967741935486e-05,
      "loss": 0.05768417716026306,
      "step": 550
    },
    {
      "epoch": 4.517171717171717,
      "grad_norm": 0.05346564203500748,
      "learning_rate": 1.2486559139784946e-05,
      "loss": 0.05670514702796936,
      "step": 560
    },
    {
      "epoch": 4.597979797979798,
      "grad_norm": 0.05779594928026199,
      "learning_rate": 1.2352150537634409e-05,
      "loss": 0.05570988059043884,
      "step": 570
    },
    {
      "epoch": 4.678787878787879,
      "grad_norm": 0.0657142698764801,
      "learning_rate": 1.2217741935483872e-05,
      "loss": 0.059663009643554685,
      "step": 580
    },
    {
      "epoch": 4.759595959595959,
      "grad_norm": 0.058478888124227524,
      "learning_rate": 1.2083333333333333e-05,
      "loss": 0.058327662944793704,
      "step": 590
    },
    {
      "epoch": 4.8404040404040405,
      "grad_norm": 0.0596800334751606,
      "learning_rate": 1.1948924731182797e-05,
      "loss": 0.05569678544998169,
      "step": 600
    },
    {
      "epoch": 4.921212121212121,
      "grad_norm": 0.05967574939131737,
      "learning_rate": 1.1814516129032258e-05,
      "loss": 0.05734652280807495,
      "step": 610
    },
    {
      "epoch": 5.0,
      "grad_norm": 0.06747253984212875,
      "learning_rate": 1.1680107526881721e-05,
      "loss": 0.05285971760749817,
      "step": 620
    },
    {
      "epoch": 5.0,
      "eval_loss": 0.05763375386595726,
      "eval_runtime": 87.3601,
      "eval_samples_per_second": 7.555,
      "eval_steps_per_second": 3.777,
      "step": 620
    },
    {
      "epoch": 5.08080808080808,
      "grad_norm": 0.0790758952498436,
      "learning_rate": 1.1545698924731183e-05,
      "loss": 0.06019992232322693,
      "step": 630
    },
    {
      "epoch": 5.161616161616162,
      "grad_norm": 0.0517873540520668,
      "learning_rate": 1.1411290322580646e-05,
      "loss": 0.055637723207473753,
      "step": 640
    },
    {
      "epoch": 5.242424242424242,
      "grad_norm": 0.06669070571660995,
      "learning_rate": 1.1276881720430109e-05,
      "loss": 0.056730836629867554,
      "step": 650
    },
    {
      "epoch": 5.3232323232323235,
      "grad_norm": 0.05337738245725632,
      "learning_rate": 1.114247311827957e-05,
      "loss": 0.0604034423828125,
      "step": 660
    },
    {
      "epoch": 5.404040404040404,
      "grad_norm": 0.06325989961624146,
      "learning_rate": 1.1008064516129034e-05,
      "loss": 0.05493579506874084,
      "step": 670
    },
    {
      "epoch": 5.484848484848484,
      "grad_norm": 0.052121955901384354,
      "learning_rate": 1.0873655913978495e-05,
      "loss": 0.05273014903068542,
      "step": 680
    },
    {
      "epoch": 5.565656565656566,
      "grad_norm": 0.06206656992435455,
      "learning_rate": 1.0739247311827958e-05,
      "loss": 0.054121744632720944,
      "step": 690
    },
    {
      "epoch": 5.646464646464646,
      "grad_norm": 0.06003660708665848,
      "learning_rate": 1.0604838709677422e-05,
      "loss": 0.053858643770217894,
      "step": 700
    },
    {
      "epoch": 5.7272727272727275,
      "grad_norm": 0.06528162211179733,
      "learning_rate": 1.0470430107526883e-05,
      "loss": 0.04857719540596008,
      "step": 710
    },
    {
      "epoch": 5.808080808080808,
      "grad_norm": 0.06653520464897156,
      "learning_rate": 1.0336021505376346e-05,
      "loss": 0.055848628282547,
      "step": 720
    },
    {
      "epoch": 5.888888888888889,
      "grad_norm": 0.06294754892587662,
      "learning_rate": 1.0201612903225808e-05,
      "loss": 0.055948066711425784,
      "step": 730
    },
    {
      "epoch": 5.96969696969697,
      "grad_norm": 0.0671958476305008,
      "learning_rate": 1.0067204301075271e-05,
      "loss": 0.05745607614517212,
      "step": 740
    },
    {
      "epoch": 6.0,
      "eval_loss": 0.05646424740552902,
      "eval_runtime": 87.3118,
      "eval_samples_per_second": 7.559,
      "eval_steps_per_second": 3.78,
      "step": 744
    },
    {
      "epoch": 6.048484848484849,
      "grad_norm": 0.06735274195671082,
      "learning_rate": 9.932795698924732e-06,
      "loss": 0.05203207135200501,
      "step": 750
    },
    {
      "epoch": 6.129292929292929,
      "grad_norm": 0.06710353493690491,
      "learning_rate": 9.798387096774194e-06,
      "loss": 0.055652952194213866,
      "step": 760
    },
    {
      "epoch": 6.21010101010101,
      "grad_norm": 0.06379822641611099,
      "learning_rate": 9.663978494623657e-06,
      "loss": 0.05838107466697693,
      "step": 770
    },
    {
      "epoch": 6.290909090909091,
      "grad_norm": 0.06253382563591003,
      "learning_rate": 9.52956989247312e-06,
      "loss": 0.05133015513420105,
      "step": 780
    },
    {
      "epoch": 6.3717171717171714,
      "grad_norm": 0.06442827731370926,
      "learning_rate": 9.395161290322582e-06,
      "loss": 0.05491199493408203,
      "step": 790
    },
    {
      "epoch": 6.452525252525253,
      "grad_norm": 0.07126863300800323,
      "learning_rate": 9.260752688172043e-06,
      "loss": 0.060243499279022214,
      "step": 800
    },
    {
      "epoch": 6.533333333333333,
      "grad_norm": 0.07112977653741837,
      "learning_rate": 9.126344086021506e-06,
      "loss": 0.048802444338798524,
      "step": 810
    },
    {
      "epoch": 6.6141414141414145,
      "grad_norm": 0.07388924062252045,
      "learning_rate": 8.991935483870968e-06,
      "loss": 0.051920390129089354,
      "step": 820
    },
    {
      "epoch": 6.694949494949495,
      "grad_norm": 0.06737921386957169,
      "learning_rate": 8.857526881720431e-06,
      "loss": 0.054844290018081665,
      "step": 830
    },
    {
      "epoch": 6.775757575757575,
      "grad_norm": 0.053981930017471313,
      "learning_rate": 8.723118279569893e-06,
      "loss": 0.050021135807037355,
      "step": 840
    },
    {
      "epoch": 6.856565656565657,
      "grad_norm": 0.06872440129518509,
      "learning_rate": 8.588709677419356e-06,
      "loss": 0.055412459373474124,
      "step": 850
    },
    {
      "epoch": 6.937373737373737,
      "grad_norm": 0.06135243922472,
      "learning_rate": 8.454301075268819e-06,
      "loss": 0.05228089690208435,
      "step": 860
    },
    {
      "epoch": 7.0,
      "eval_loss": 0.055541183799505234,
      "eval_runtime": 87.5355,
      "eval_samples_per_second": 7.54,
      "eval_steps_per_second": 3.77,
      "step": 868
    },
    {
      "epoch": 7.016161616161616,
      "grad_norm": 0.06925718486309052,
      "learning_rate": 8.31989247311828e-06,
      "loss": 0.05612342953681946,
      "step": 870
    },
    {
      "epoch": 7.096969696969697,
      "grad_norm": 0.06348288059234619,
      "learning_rate": 8.185483870967744e-06,
      "loss": 0.05649881362915039,
      "step": 880
    },
    {
      "epoch": 7.177777777777778,
      "grad_norm": 0.06971318274736404,
      "learning_rate": 8.051075268817205e-06,
      "loss": 0.05321135520935059,
      "step": 890
    },
    {
      "epoch": 7.2585858585858585,
      "grad_norm": 0.06488990038633347,
      "learning_rate": 7.916666666666667e-06,
      "loss": 0.05552859306335449,
      "step": 900
    },
    {
      "epoch": 7.33939393939394,
      "grad_norm": 0.06948307156562805,
      "learning_rate": 7.78225806451613e-06,
      "loss": 0.05311954617500305,
      "step": 910
    },
    {
      "epoch": 7.42020202020202,
      "grad_norm": 0.07207676023244858,
      "learning_rate": 7.647849462365591e-06,
      "loss": 0.05326292514801025,
      "step": 920
    },
    {
      "epoch": 7.501010101010101,
      "grad_norm": 0.061991043388843536,
      "learning_rate": 7.513440860215054e-06,
      "loss": 0.05025961399078369,
      "step": 930
    },
    {
      "epoch": 7.581818181818182,
      "grad_norm": 0.06286507099866867,
      "learning_rate": 7.379032258064517e-06,
      "loss": 0.05532093644142151,
      "step": 940
    },
    {
      "epoch": 7.6626262626262625,
      "grad_norm": 0.06340993940830231,
      "learning_rate": 7.244623655913979e-06,
      "loss": 0.049476778507232665,
      "step": 950
    },
    {
      "epoch": 7.743434343434344,
      "grad_norm": 0.060668542981147766,
      "learning_rate": 7.110215053763441e-06,
      "loss": 0.047853332757949826,
      "step": 960
    },
    {
      "epoch": 7.824242424242424,
      "grad_norm": 0.07753355801105499,
      "learning_rate": 6.9758064516129046e-06,
      "loss": 0.05584861040115356,
      "step": 970
    },
    {
      "epoch": 7.9050505050505055,
      "grad_norm": 0.06634362787008286,
      "learning_rate": 6.841397849462366e-06,
      "loss": 0.05703045725822449,
      "step": 980
    },
    {
      "epoch": 7.985858585858586,
      "grad_norm": 0.06869083642959595,
      "learning_rate": 6.706989247311828e-06,
      "loss": 0.0513882040977478,
      "step": 990
    },
    {
      "epoch": 8.0,
      "eval_loss": 0.05481649562716484,
      "eval_runtime": 87.3295,
      "eval_samples_per_second": 7.558,
      "eval_steps_per_second": 3.779,
      "step": 992
    },
    {
      "epoch": 8.064646464646465,
      "grad_norm": 0.06696917861700058,
      "learning_rate": 6.572580645161291e-06,
      "loss": 0.053405582904815674,
      "step": 1000
    },
    {
      "epoch": 8.145454545454545,
      "grad_norm": 0.07019365578889847,
      "learning_rate": 6.438172043010753e-06,
      "loss": 0.055020928382873535,
      "step": 1010
    },
    {
      "epoch": 8.226262626262626,
      "grad_norm": 0.05538204312324524,
      "learning_rate": 6.303763440860215e-06,
      "loss": 0.05176675319671631,
      "step": 1020
    },
    {
      "epoch": 8.307070707070707,
      "grad_norm": 0.07529964298009872,
      "learning_rate": 6.169354838709678e-06,
      "loss": 0.05506412982940674,
      "step": 1030
    },
    {
      "epoch": 8.387878787878789,
      "grad_norm": 0.06751428544521332,
      "learning_rate": 6.034946236559141e-06,
      "loss": 0.05155418515205383,
      "step": 1040
    },
    {
      "epoch": 8.468686868686868,
      "grad_norm": 0.06550341844558716,
      "learning_rate": 5.900537634408603e-06,
      "loss": 0.04855434596538544,
      "step": 1050
    },
    {
      "epoch": 8.54949494949495,
      "grad_norm": 0.06394799798727036,
      "learning_rate": 5.7661290322580655e-06,
      "loss": 0.054040569067001346,
      "step": 1060
    },
    {
      "epoch": 8.63030303030303,
      "grad_norm": 0.07164719700813293,
      "learning_rate": 5.631720430107528e-06,
      "loss": 0.05371541380882263,
      "step": 1070
    },
    {
      "epoch": 8.71111111111111,
      "grad_norm": 0.07032275944948196,
      "learning_rate": 5.497311827956989e-06,
      "loss": 0.054386460781097413,
      "step": 1080
    },
    {
      "epoch": 8.791919191919192,
      "grad_norm": 0.06001463904976845,
      "learning_rate": 5.362903225806452e-06,
      "loss": 0.04937349259853363,
      "step": 1090
    },
    {
      "epoch": 8.872727272727273,
      "grad_norm": 0.07663878053426743,
      "learning_rate": 5.228494623655914e-06,
      "loss": 0.051903337240219116,
      "step": 1100
    },
    {
      "epoch": 8.953535353535354,
      "grad_norm": 0.0635543093085289,
      "learning_rate": 5.094086021505376e-06,
      "loss": 0.05292636156082153,
      "step": 1110
    },
    {
      "epoch": 9.0,
      "eval_loss": 0.0542522557079792,
      "eval_runtime": 87.4611,
      "eval_samples_per_second": 7.546,
      "eval_steps_per_second": 3.773,
      "step": 1116
    }
  ],
  "logging_steps": 10,
  "max_steps": 1488,
  "num_input_tokens_seen": 0,
  "num_train_epochs": 12,
  "save_steps": 500,
  "stateful_callbacks": {
    "EarlyStoppingCallback": {
      "args": {
        "early_stopping_patience": 1,
        "early_stopping_threshold": 0.0
      },
      "attributes": {
        "early_stopping_patience_counter": 0
      }
    },
    "TrainerControl": {
      "args": {
        "should_epoch_stop": false,
        "should_evaluate": false,
        "should_log": false,
        "should_save": true,
        "should_training_stop": false
      },
      "attributes": {}
    }
  },
  "total_flos": 7.197060636868608e+16,
  "train_batch_size": 2,
  "trial_name": null,
  "trial_params": null
}
