{
  "best_global_step": 620,
  "best_metric": 0.05763375386595726,
  "best_model_checkpoint": "content/drive/models/training_output_4/checkpoint-620",
  "epoch": 5.0,
  "eval_steps": 500,
  "global_step": 620,
  "is_hyper_param_search": false,
  "is_local_process_zero": true,
  "is_world_process_zero": true,
  "log_history": [
    {
      "epoch": 0.08080808080808081,
      "grad_norm": 13.015850067138672,
      "learning_rate": 1.9879032258064516e-05,
      "loss": 5.578479766845703,
      "step": 10
    },
    {
      "epoch": 0.16161616161616163,
      "grad_norm": 12.306844711303711,
      "learning_rate": 1.974462365591398e-05,
      "loss": 4.433839797973633,
      "step": 20
    },
    {
      "epoch": 0.24242424242424243,
      "grad_norm": 11.609118461608887,
      "learning_rate": 1.9610215053763443e-05,
      "loss": 3.170028305053711,
      "step": 30
    },
    {
      "epoch": 0.32323232323232326,
      "grad_norm": 9.40298080444336,
      "learning_rate": 1.9475806451612903e-05,
      "loss": 1.8761165618896485,
      "step": 40
    },
    {
      "epoch": 0.40404040404040403,
      "grad_norm": 5.286498069763184,
      "learning_rate": 1.9341397849462366e-05,
      "loss": 0.8735734939575195,
      "step": 50
    },
    {
      "epoch": 0.48484848484848486,
      "grad_norm": 1.7800805568695068,
      "learning_rate": 1.920698924731183e-05,
      "loss": 0.31956870555877687,
      "step": 60
    },
    {
      "epoch": 0.5656565656565656,
      "grad_norm": 0.40217727422714233,
      "learning_rate": 1.9072580645161292e-05,
      "loss": 0.11500203609466553,
      "step": 70
    },
    {
      "epoch": 0.6464646464646465,
      "grad_norm": 0.1334134191274643,
      "learning_rate": 1.8938172043010755e-05,
      "loss": 0.08108080625534057,
      "step": 80
    },
    {
      "epoch": 0.7272727272727273,
      "grad_norm": 0.11144118756055832,
      "learning_rate": 1.8803763440860215e-05,
      "loss": 0.070091712474823,
      "step": 90
    },
    {
      "epoch": 0.8080808080808081,
      "grad_norm": 0.11706991493701935,
      "learning_rate": 1.8669354838709678e-05,
      "loss": 0.0744411289691925,
      "step": 100
    },
    {
      "epoch": 0.8888888888888888,
      "grad_norm": 0.10010116547346115,
      "learning_rate": 1.853494623655914e-05,
      "loss": 0.07352244853973389,
      "step": 110
    },
    {
      "epoch": 0.9696969696969697,
      "grad_norm": 0.11633072048425674,
      "learning_rate": 1.8400537634408605e-05,
      "loss": 0.06839484572410584,
      "step": 120
    },
    {
      "epoch": 1.0,
      "eval_loss": 0.06795526295900345,
      "eval_runtime": 87.4745,
      "eval_samples_per_second": 7.545,
      "eval_steps_per_second": 3.773,
      "step": 124
    },
    {
      "epoch": 1.0484848484848486,
      "grad_norm": 0.0772845596075058,
      "learning_rate": 1.8266129032258068e-05,
      "loss": 0.06486396193504333,
      "step": 130
    },
    {
      "epoch": 1.1292929292929292,
      "grad_norm": 0.06823030859231949,
      "learning_rate": 1.8131720430107528e-05,
      "loss": 0.06288682222366333,
      "step": 140
    },
    {
      "epoch": 1.2101010101010101,
      "grad_norm": 0.06566287577152252,
      "learning_rate": 1.799731182795699e-05,
      "loss": 0.06069457530975342,
      "step": 150
    },
    {
      "epoch": 1.290909090909091,
      "grad_norm": 0.0790524035692215,
      "learning_rate": 1.7862903225806454e-05,
      "loss": 0.06440240740776063,
      "step": 160
    },
    {
      "epoch": 1.3717171717171717,
      "grad_norm": 0.07850462198257446,
      "learning_rate": 1.7728494623655917e-05,
      "loss": 0.0628172755241394,
      "step": 170
    },
    {
      "epoch": 1.4525252525252526,
      "grad_norm": 0.0760226920247078,
      "learning_rate": 1.759408602150538e-05,
      "loss": 0.07023220658302307,
      "step": 180
    },
    {
      "epoch": 1.5333333333333332,
      "grad_norm": 0.11974471807479858,
      "learning_rate": 1.745967741935484e-05,
      "loss": 0.06517117619514465,
      "step": 190
    },
    {
      "epoch": 1.614141414141414,
      "grad_norm": 0.07063767313957214,
      "learning_rate": 1.73252688172043e-05,
      "loss": 0.06495907306671142,
      "step": 200
    },
    {
      "epoch": 1.694949494949495,
      "grad_norm": 0.06868203729391098,
      "learning_rate": 1.7190860215053763e-05,
      "loss": 0.06686801314353943,
      "step": 210
    },
    {
      "epoch": 1.7757575757575759,
      "grad_norm": 0.06420079618692398,
      "learning_rate": 1.7056451612903226e-05,
      "loss": 0.06207112669944763,
      "step": 220
    },
    {
      "epoch": 1.8565656565656565,
      "grad_norm": 0.08376576751470566,
      "learning_rate": 1.692204301075269e-05,
      "loss": 0.06316893100738526,
      "step": 230
    },
    {
      "epoch": 1.9373737373737374,
      "grad_norm": 0.08368518203496933,
      "learning_rate": 1.6787634408602153e-05,
      "loss": 0.06262634396553039,
      "step": 240
    },
    {
      "epoch": 2.0,
      "eval_loss": 0.0632142722606659,
      "eval_runtime": 88.0376,
      "eval_samples_per_second": 7.497,
      "eval_steps_per_second": 3.748,
      "step": 248
    },
    {
      "epoch": 2.0161616161616163,
      "grad_norm": 0.0745951384305954,
      "learning_rate": 1.6653225806451612e-05,
      "loss": 0.06384766697883607,
      "step": 250
    },
    {
      "epoch": 2.096969696969697,
      "grad_norm": 0.06934960931539536,
      "learning_rate": 1.6518817204301076e-05,
      "loss": 0.06773784160614013,
      "step": 260
    },
    {
      "epoch": 2.1777777777777776,
      "grad_norm": 0.05930635333061218,
      "learning_rate": 1.638440860215054e-05,
      "loss": 0.06191051602363586,
      "step": 270
    },
    {
      "epoch": 2.2585858585858585,
      "grad_norm": 0.05867518112063408,
      "learning_rate": 1.6250000000000002e-05,
      "loss": 0.06206596493721008,
      "step": 280
    },
    {
      "epoch": 2.3393939393939394,
      "grad_norm": 0.05699066072702408,
      "learning_rate": 1.6115591397849465e-05,
      "loss": 0.05760701894760132,
      "step": 290
    },
    {
      "epoch": 2.4202020202020202,
      "grad_norm": 0.06587546318769455,
      "learning_rate": 1.5981182795698925e-05,
      "loss": 0.05909337401390076,
      "step": 300
    },
    {
      "epoch": 2.501010101010101,
      "grad_norm": 0.07658211141824722,
      "learning_rate": 1.5846774193548388e-05,
      "loss": 0.06593965291976929,
      "step": 310
    },
    {
      "epoch": 2.581818181818182,
      "grad_norm": 0.05009419471025467,
      "learning_rate": 1.571236559139785e-05,
      "loss": 0.058328425884246825,
      "step": 320
    },
    {
      "epoch": 2.6626262626262625,
      "grad_norm": 0.06939257681369781,
      "learning_rate": 1.5577956989247314e-05,
      "loss": 0.05181876420974731,
      "step": 330
    },
    {
      "epoch": 2.7434343434343433,
      "grad_norm": 0.06968538463115692,
      "learning_rate": 1.5443548387096778e-05,
      "loss": 0.06490702629089355,
      "step": 340
    },
    {
      "epoch": 2.824242424242424,
      "grad_norm": 0.06620388478040695,
      "learning_rate": 1.5309139784946237e-05,
      "loss": 0.05864723920822144,
      "step": 350
    },
    {
      "epoch": 2.905050505050505,
      "grad_norm": 0.08496524393558502,
      "learning_rate": 1.51747311827957e-05,
      "loss": 0.05889002680778503,
      "step": 360
    },
    {
      "epoch": 2.985858585858586,
      "grad_norm": 0.07690040022134781,
      "learning_rate": 1.5040322580645164e-05,
      "loss": 0.05922978520393372,
      "step": 370
    },
    {
      "epoch": 3.0,
      "eval_loss": 0.06085158884525299,
      "eval_runtime": 88.1587,
      "eval_samples_per_second": 7.486,
      "eval_steps_per_second": 3.743,
      "step": 372
    },
    {
      "epoch": 3.0646464646464646,
      "grad_norm": 0.06398389488458633,
      "learning_rate": 1.4905913978494624e-05,
      "loss": 0.06704699397087097,
      "step": 380
    },
    {
      "epoch": 3.1454545454545455,
      "grad_norm": 0.06622301042079926,
      "learning_rate": 1.4771505376344087e-05,
      "loss": 0.05670986175537109,
      "step": 390
    },
    {
      "epoch": 3.2262626262626264,
      "grad_norm": 0.06247016414999962,
      "learning_rate": 1.4637096774193548e-05,
      "loss": 0.06026037335395813,
      "step": 400
    },
    {
      "epoch": 3.3070707070707073,
      "grad_norm": 0.05598907545208931,
      "learning_rate": 1.4502688172043011e-05,
      "loss": 0.05801964998245239,
      "step": 410
    },
    {
      "epoch": 3.3878787878787877,
      "grad_norm": 0.06981255859136581,
      "learning_rate": 1.4368279569892473e-05,
      "loss": 0.058812510967254636,
      "step": 420
    },
    {
      "epoch": 3.4686868686868686,
      "grad_norm": 0.05953635275363922,
      "learning_rate": 1.4233870967741936e-05,
      "loss": 0.05832362174987793,
      "step": 430
    },
    {
      "epoch": 3.5494949494949495,
      "grad_norm": 0.06131282076239586,
      "learning_rate": 1.40994623655914e-05,
      "loss": 0.05836346745491028,
      "step": 440
    },
    {
      "epoch": 3.6303030303030304,
      "grad_norm": 0.06660293787717819,
      "learning_rate": 1.396505376344086e-05,
      "loss": 0.054709017276763916,
      "step": 450
    },
    {
      "epoch": 3.7111111111111112,
      "grad_norm": 0.07622505724430084,
      "learning_rate": 1.3830645161290324e-05,
      "loss": 0.06122797131538391,
      "step": 460
    },
    {
      "epoch": 3.7919191919191917,
      "grad_norm": 0.05464499816298485,
      "learning_rate": 1.3696236559139785e-05,
      "loss": 0.053363478183746337,
      "step": 470
    },
    {
      "epoch": 3.8727272727272726,
      "grad_norm": 0.06807393580675125,
      "learning_rate": 1.3561827956989249e-05,
      "loss": 0.060813242197036745,
      "step": 480
    },
    {
      "epoch": 3.9535353535353535,
      "grad_norm": 0.06430447846651077,
      "learning_rate": 1.3427419354838712e-05,
      "loss": 0.059005504846572875,
      "step": 490
    },
    {
      "epoch": 4.0,
      "eval_loss": 0.05907474458217621,
      "eval_runtime": 87.5505,
      "eval_samples_per_second": 7.539,
      "eval_steps_per_second": 3.769,
      "step": 496
    },
    {
      "epoch": 4.0323232323232325,
      "grad_norm": 0.04845976084470749,
      "learning_rate": 1.3293010752688173e-05,
      "loss": 0.05912242531776428,
      "step": 500
    },
    {
      "epoch": 4.113131313131313,
      "grad_norm": 0.0573616661131382,
      "learning_rate": 1.3158602150537636e-05,
      "loss": 0.058849912881851194,
      "step": 510
    },
    {
      "epoch": 4.193939393939394,
      "grad_norm": 0.06972318887710571,
      "learning_rate": 1.3024193548387098e-05,
      "loss": 0.05605725049972534,
      "step": 520
    },
    {
      "epoch": 4.274747474747475,
      "grad_norm": 0.058717187494039536,
      "learning_rate": 1.2889784946236561e-05,
      "loss": 0.05776209235191345,
      "step": 530
    },
    {
      "epoch": 4.355555555555555,
      "grad_norm": 0.052418775856494904,
      "learning_rate": 1.2755376344086023e-05,
      "loss": 0.053939682245254514,
      "step": 540
    },
    {
      "epoch": 4.4363636363636365,
      "grad_norm": 0.06309913098812103,
      "learning_rate": 1.2620967741935486e-05,
      "loss": 0.05768417716026306,
      "step": 550
    },
    {
      "epoch": 4.517171717171717,
      "grad_norm": 0.05346564203500748,
      "learning_rate": 1.2486559139784946e-05,
      "loss": 0.05670514702796936,
      "step": 560
    },
    {
      "epoch": 4.597979797979798,
      "grad_norm": 0.05779594928026199,
      "learning_rate": 1.2352150537634409e-05,
      "loss": 0.05570988059043884,
      "step": 570
    },
    {
      "epoch": 4.678787878787879,
      "grad_norm": 0.0657142698764801,
      "learning_rate": 1.2217741935483872e-05,
      "loss": 0.059663009643554685,
      "step": 580
    },
    {
      "epoch": 4.759595959595959,
      "grad_norm": 0.058478888124227524,
      "learning_rate": 1.2083333333333333e-05,
      "loss": 0.058327662944793704,
      "step": 590
    },
    {
      "epoch": 4.8404040404040405,
      "grad_norm": 0.0596800334751606,
      "learning_rate": 1.1948924731182797e-05,
      "loss": 0.05569678544998169,
      "step": 600
    },
    {
      "epoch": 4.921212121212121,
      "grad_norm": 0.05967574939131737,
      "learning_rate": 1.1814516129032258e-05,
      "loss": 0.05734652280807495,
      "step": 610
    },
    {
      "epoch": 5.0,
      "grad_norm": 0.06747253984212875,
      "learning_rate": 1.1680107526881721e-05,
      "loss": 0.05285971760749817,
      "step": 620
    },
    {
      "epoch": 5.0,
      "eval_loss": 0.05763375386595726,
      "eval_runtime": 87.3601,
      "eval_samples_per_second": 7.555,
      "eval_steps_per_second": 3.777,
      "step": 620
    }
  ],
  "logging_steps": 10,
  "max_steps": 1488,
  "num_input_tokens_seen": 0,
  "num_train_epochs": 12,
  "save_steps": 500,
  "stateful_callbacks": {
    "EarlyStoppingCallback": {
      "args": {
        "early_stopping_patience": 1,
        "early_stopping_threshold": 0.0
      },
      "attributes": {
        "early_stopping_patience_counter": 0
      }
    },
    "TrainerControl": {
      "args": {
        "should_epoch_stop": false,
        "should_evaluate": false,
        "should_log": false,
        "should_save": true,
        "should_training_stop": false
      },
      "attributes": {}
    }
  },
  "total_flos": 3.99836702048256e+16,
  "train_batch_size": 2,
  "trial_name": null,
  "trial_params": null
}
